{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1593ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install evostencils package with requirements\n",
    "pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94db57b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the ExaStencils framework\n",
    "# sudo apt-get install -y g++ java\n",
    "!wget -nc https://github.com/lssfau/ExaStencils/archive/refs/tags/v1.1.zip\n",
    "!wget -nc https://github.com/sbt/sbt/releases/download/v1.8.0/sbt-1.8.0.zip\n",
    "!unzip -n v1.1.zip && mv -vn ExaStencils-1.1 exastencils\n",
    "!unzip -n sbt-1.8.0.zip\n",
    "%cd exastencils\n",
    "!../sbt/bin/sbt compile\n",
    "!../sbt/bin/sbt assembly\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c59dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Install LFA Lab for convergence estimation\n",
    "# sudo apt-get install -y cmake swig libeigen3-dev liblapack-dev\n",
    "!git clone https://github.com/hrittich/lfa-lab.git lfa-lab\n",
    "!cmake -DWITH_TESTS=FALSE lfa-lab\n",
    "!make -j4 lfa-lab\n",
    "%cd lfa-lab\n",
    "!make install\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886c92ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evostencils.optimization.program import Optimizer\n",
    "from evostencils.code_generation.exastencils import ProgramGenerator\n",
    "import os\n",
    "import sys\n",
    "from mpi4py import MPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756360ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = f'{os.getcwd()}'\n",
    "# Path to the ExaStencils compiler\n",
    "compiler_path = f'{cwd}/exastencils/Compiler/Compiler.jar'\n",
    "# Path to base folder\n",
    "base_path = f'{cwd}/example_problems'\n",
    "# Relative path to platform file (from base folder)\n",
    "platform_path = f'lib/linux.platform'\n",
    "# Example problem from L2\n",
    "# Relative path to settings file (from base folder)\n",
    "settings_path = f'Poisson/2D_FD_Poisson_fromL2.settings'\n",
    "knowledge_path = f'Poisson/2D_FD_Poisson_fromL2.knowledge'\n",
    "cycle_name = \"gen_mgCycle\"  # Default name\n",
    "# Additional global parameter values within the PDE system\n",
    "pde_parameter_values = None\n",
    "# The maximum number of iterations considered acceptable for a solver\n",
    "solver_iteration_limit = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dea7ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special treatment of parameters for the Helmholtz example\n",
    "if \"Helmholtz\" in knowledge_path or \"Helmholtz\" in settings_path:\n",
    "    values = [80.0 * 2.0**i for i in range(100)]\n",
    "    pde_parameter_values = {'k': values}\n",
    "    solver_iteration_limit = 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf84ed52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "nprocs = comm.Get_size()\n",
    "mpi_rank = comm.Get_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ccb33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only recommended for testing purposes\n",
    "# Use model based estimation instead of code generation and model_based_prediction\n",
    "model_based_estimation = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdd0a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "program_generator = ProgramGenerator(compiler_path, base_path, settings_path, knowledge_path, platform_path, mpi_rank, \n",
    "                                     cycle_name=cycle_name, model_based_estimation=model_based_estimation,\n",
    "                                     solver_iteration_limit=solver_iteration_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02286416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain extracted information from program generator\n",
    "dimension = program_generator.dimension  # Dimensionality of the problem\n",
    "finest_grid = program_generator.finest_grid  # Representation of the finest grid\n",
    "coarsening_factors = program_generator.coarsening_factor\n",
    "min_level = program_generator.min_level  # Minimum discretization level\n",
    "max_level = program_generator.max_level  # Maximum discretization level\n",
    "equations = program_generator.equations  # System of PDEs in SymPy\n",
    "operators = program_generator.operators  # Discretized differential operators\n",
    "fields = program_generator.fields  # Variables that occur within system of PDEs\n",
    "problem_name = program_generator.problem_name\n",
    "convergence_evaluator = None\n",
    "performance_evaluator = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e05df7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_based_estimation:\n",
    "    # Create convergence and performance evaluator objects\n",
    "    # Convergence evaluation requires a working LFA Lab installation!\n",
    "    # Only needed when a model-based estimation should be used within the optimization\n",
    "    # (Not recommended due to the limitations, but useful for testing)\n",
    "    from evostencils.model_based_estimation.convergence import ConvergenceEvaluator\n",
    "    from evostencils.model_based_estimation.performance import PerformanceEvaluator\n",
    "    convergence_evaluator = ConvergenceEvaluator(dimension, coarsening_factors, finest_grid)\n",
    "    # Peak FLOP performance of the machine\n",
    "    peak_flops = 16 * 6 * 2.6 * 1e9\n",
    "    # Peak memory bandwidth of the machine\n",
    "    peak_bandwidth = 45.8 * 1e9\n",
    "    # Number of bytes per word\n",
    "    bytes_per_word = 8  # Double = 64 Bit = 8 Bytes\n",
    "    performance_evaluator = PerformanceEvaluator(peak_flops, peak_bandwidth, bytes_per_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28bb48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mpi_rank == 0 and not os.path.exists(f'{cwd}/{problem_name}'):\n",
    "    # Create directory for checkpoints and output data\n",
    "    os.makedirs(f'{cwd}/{problem_name}')\n",
    "# Path to directory for storing checkpoints\n",
    "checkpoint_directory_path = f'{cwd}/{problem_name}/checkpoints_{mpi_rank}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2752c9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Optimizer(dimension, finest_grid, coarsening_factors, min_level, max_level, equations, operators, fields, \n",
    "                      mpi_comm=comm, mpi_rank=mpi_rank, number_of_mpi_processes=nprocs, program_generator=program_generator, \n",
    "                      convergence_evaluator=convergence_evaluator, performance_evaluator=performance_evaluator, \n",
    "                      checkpoint_directory_path=checkpoint_directory_path)\n",
    "# Option to split the optimization into multiple runs,\n",
    "# where each run is only performed on a subrange of the discretization hierarchy starting at the top (finest grid)\n",
    "# (Not recommended for code-generation based model_based_prediction)\n",
    "levels_per_run = max_level - min_level\n",
    "if model_based_estimation:\n",
    "    # Model-based estimation only feasible for up to 2 levels per run\n",
    "    levels_per_run = 2\n",
    "assert levels_per_run <= 5, \"Can not optimize more than 5 levels\"\n",
    "# Choose optimization method\n",
    "optimization_method = optimizer.NSGAII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4832a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option to use random search instead of crossover and mutation to create new individuals\n",
    "use_random_search = False\n",
    "\n",
    "mu_ = 8  # Population size\n",
    "lambda_ = 8  # Number of offspring\n",
    "generations = 10  # Number of generations\n",
    "population_initialization_factor = 4  # Multiply mu_ by this factor to set the initial population size\n",
    "\n",
    "# Number of generations after which a generalization is performed\n",
    "# This is achieved by incrementing min_level and max_level within the optimization\n",
    "# Such that a larger (and potentially more difficult) instance of the same problem is considered in subsequent generations\n",
    "generalization_interval = 50\n",
    "crossover_probability = 0.9\n",
    "mutation_probability = 1.0 - crossover_probability\n",
    "node_replacement_probability = 0.1  # Probability to perform mutation by altering a single node in the tree\n",
    "evaluation_samples = 3  # Number of evaluation samples\n",
    "maximum_local_system_size = 4  # Maximum size of the local system solved within each step of a block smoother\n",
    "# Option to continue from the checkpoint of a previous optimization\n",
    "# Warning: So far no check is performed whether the checkpoint is compatible with the current optimization setting\n",
    "continue_from_checkpoint = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3319f090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return values of the optimization\n",
    "# program: Grammar string representing the multigrid method on the topmost levels\n",
    "# dsl_code: ExaSlang program string representing the multigrid solver functions\n",
    "# pops: Populations at the end of each optimization run on the respective subrange of the discretization hierarchy\n",
    "# stats: Statistics structure (data structure provided by the DEAP framework)\n",
    "# hofs: Hall-of-fames at the end of each optimization run on the respective subrange of the discretization hierarchy\n",
    "program, dsl_code, pops, stats, hofs = optimizer.evolutionary_optimization(optimization_method=optimization_method, \n",
    "                                                                 use_random_search=use_random_search, \n",
    "                                                                 mu_=mu_, lambda_=lambda_, \n",
    "                                                                 population_initialization_factor=population_initialization_factor,\n",
    "                                                                 generations=generations, \n",
    "                                                                 generalization_interval=generalization_interval,\n",
    "                                                                 crossover_probability=crossover_probability,\n",
    "                                                                 mutation_probability=mutation_probability,\n",
    "                                                                 node_replacement_probability=node_replacement_probability,\n",
    "                                                                 levels_per_run=levels_per_run,\n",
    "                                                                 evaluation_samples=evaluation_samples,\n",
    "                                                                 maximum_local_system_size=maximum_local_system_size,\n",
    "                                                                 model_based_estimation=model_based_estimation,\n",
    "                                                                 pde_parameter_values=pde_parameter_values,\n",
    "                                                                 continue_from_checkpoint=continue_from_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0173b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the outcome of the optimization and store the data and statistics\n",
    "if mpi_rank == 0:\n",
    "    print(f'\\nExaSlang Code:\\n{dsl_code}\\n', flush=True)\n",
    "    if not os.path.exists(f'./{problem_name}'):\n",
    "        os.makedirs(f'./{problem_name}')\n",
    "    j = 0\n",
    "    log_dir_name = f'./{problem_name}/data_{j}'\n",
    "    while os.path.exists(log_dir_name):\n",
    "        j += 1\n",
    "        log_dir_name = f'./{problem_name}/data_{j}'\n",
    "    os.makedirs(log_dir_name)\n",
    "    for i, log in enumerate(stats):\n",
    "        optimizer.dump_data_structure(log, f\"{log_dir_name}/log_{i}.p\")\n",
    "    for i, pop in enumerate(pops):\n",
    "        optimizer.dump_data_structure(pop, f\"{log_dir_name}/pop_{i}.p\")\n",
    "    for i, hof in enumerate(hofs):\n",
    "        hof_dir = f'{log_dir_name}/hof_{i}'\n",
    "        os.makedirs(hof_dir)\n",
    "        for j, ind in enumerate(hof):\n",
    "            with open(f'{hof_dir}/individual_{j}.txt', 'w') as grammar_file:\n",
    "                grammar_file.write(str(ind) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

2024-08-13 10:00:05.529 | INFO     | __main__:main:60 - ======================== Args ========================
2024-08-13 10:00:05.529 | INFO     | __main__:main:62 - structure               unet
2024-08-13 10:00:05.529 | INFO     | __main__:main:62 - downsampling_policy             lerp
2024-08-13 10:00:05.529 | INFO     | __main__:main:62 - upsampling_policy               lerp
2024-08-13 10:00:05.530 | INFO     | __main__:main:62 - num_iterations          16
2024-08-13 10:00:05.530 | INFO     | __main__:main:62 - relative_tolerance              1e-06
2024-08-13 10:00:05.530 | INFO     | __main__:main:62 - initialize_x0           random
2024-08-13 10:00:05.530 | INFO     | __main__:main:62 - num_mg_layers           6
2024-08-13 10:00:05.530 | INFO     | __main__:main:62 - num_mg_pre_smoothing            2
2024-08-13 10:00:05.530 | INFO     | __main__:main:62 - num_mg_post_smoothing           2
2024-08-13 10:00:05.530 | INFO     | __main__:main:62 - activation              none
2024-08-13 10:00:05.530 | INFO     | __main__:main:62 - initialize_trainable_parameters         default
2024-08-13 10:00:05.530 | INFO     | __main__:main:62 - optimizer               LBFGS
2024-08-13 10:00:05.530 | INFO     | __main__:main:62 - scheduler               ['step', '1', '0.99']
2024-08-13 10:00:05.530 | INFO     | __main__:main:62 - initial_lr              0.05
2024-08-13 10:00:05.530 | INFO     | __main__:main:62 - lambda_1                1
2024-08-13 10:00:05.530 | INFO     | __main__:main:62 - lambda_2                1
2024-08-13 10:00:05.530 | INFO     | __main__:main:62 - start_epoch             0
2024-08-13 10:00:05.530 | INFO     | __main__:main:62 - max_epoch               1
2024-08-13 10:00:05.531 | INFO     | __main__:main:62 - save_every              1
2024-08-13 10:00:05.531 | INFO     | __main__:main:62 - evaluate_every          5
2024-08-13 10:00:05.531 | INFO     | __main__:main:62 - dataset_root            /home/hadrien/Applications/mg_pytorch/evostencils/scripts/data/
2024-08-13 10:00:05.531 | INFO     | __main__:main:62 - num_workers             22
2024-08-13 10:00:05.531 | INFO     | __main__:main:62 - batch_size              1
2024-08-13 10:00:05.531 | INFO     | __main__:main:62 - device          cuda
2024-08-13 10:00:05.531 | INFO     | __main__:main:62 - checkpoint_root         /home/hadrien/Applications/mg_pytorch/evostencils/scripts/train/checkpoints
2024-08-13 10:00:05.531 | INFO     | __main__:main:62 - load_experiment         None
2024-08-13 10:00:05.531 | INFO     | __main__:main:62 - load_epoch              None
2024-08-13 10:00:05.531 | INFO     | __main__:main:62 - seed            946700412
2024-08-13 10:00:05.531 | INFO     | __main__:main:62 - deterministic           False
2024-08-13 10:00:05.531 | INFO     | __main__:main:63 - ======================================================

2024-08-13 10:00:05.531 | INFO     | __main__:main:67 - [Train] Using device cuda
2024-08-13 10:00:05.531 | INFO     | __main__:main:76 - [Train] Do not enforce deterministic algorithms, cudnn benchmark enabled
2024-08-13 10:00:05.532 | INFO     | __main__:main:81 - [Train] Manual seed PyTorch with seed 946700412

Parameter containing:
tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=torch.float64,
       requires_grad=True)
2024-08-13 10:00:05.859 | INFO     | evostencils.code_generation.trainer:__init__:138 - [Trainer] 10 training data loaded from /home/hadrien/Applications/mg_pytorch/evostencils/scripts/data/train
2024-08-13 10:00:05.859 | INFO     | evostencils.code_generation.trainer:__init__:148 - [Trainer] 0 evaluation data loaded from /home/hadrien/Applications/mg_pytorch/evostencils/scripts/data/evaluate

loss_x: tensor(13.7099, device='cuda:0', dtype=torch.float64,
       grad_fn=<MseLossBackward0>)
loss_x: tensor(0.0375, device='cuda:0', dtype=torch.float64,
       grad_fn=<MseLossBackward0>)
loss_x: tensor(0.0004, device='cuda:0', dtype=torch.float64,
       grad_fn=<MseLossBackward0>)
loss_x: tensor(0.0005, device='cuda:0', dtype=torch.float64,
       grad_fn=<MseLossBackward0>)
loss_x: tensor(0.0021, device='cuda:0', dtype=torch.float64,
       grad_fn=<MseLossBackward0>)
loss_x: tensor(0.0008, device='cuda:0', dtype=torch.float64,
       grad_fn=<MseLossBackward0>)
loss_x: tensor(0.0036, device='cuda:0', dtype=torch.float64,
       grad_fn=<MseLossBackward0>)
loss_x: tensor(0.0027, device='cuda:0', dtype=torch.float64,
       grad_fn=<MseLossBackward0>)
loss_x: tensor(0.0023, device='cuda:0', dtype=torch.float64,
       grad_fn=<MseLossBackward0>)
loss_x: tensor(0.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<MseLossBackward0>)
2024-08-13 10:00:31.691 | INFO     | evostencils.code_generation.trainer:train:209 - trainable omega = Parameter containing:
tensor([[0.4433, 0.4433, 0.4433, 0.4433, 0.4433, 0.4433, 0.4433, 0.4433, 0.4433,
         0.4433],
        [0.4374, 0.4374, 0.4374, 0.4374, 0.4374, 0.4374, 0.4374, 0.4374, 0.4374,
         0.4374],
        [1.0535, 1.0535, 1.0535, 1.0534, 1.0534, 1.0535, 1.0536, 1.0535, 1.0535,
         1.0534],
        [2.2483, 2.2483, 2.2483, 2.2483, 2.2483, 2.2483, 2.2483, 2.2483, 2.2483,
         2.2483],
        [1.8381, 1.8381, 1.8381, 1.8381, 1.8381, 1.8381, 1.8381, 1.8381, 1.8381,
         1.8381],
        [1.7714, 1.7714, 1.7714, 1.7714, 1.7714, 1.7714, 1.7714, 1.7714, 1.7714,
         1.7714],
        [1.5193, 1.5193, 1.5193, 1.5193, 1.5193, 1.5193, 1.5193, 1.5193, 1.5193,
         1.5193],
        [1.3322, 1.3322, 1.3322, 1.3322, 1.3322, 1.3322, 1.3322, 1.3322, 1.3322,
         1.3322],
        [1.0278, 1.0278, 1.0278, 1.0278, 1.0278, 1.0278, 1.0278, 1.0278, 1.0278,
         1.0278]], dtype=torch.float64, requires_grad=True), trainable weight = 0, time = 0.013877153396606445, conv_factor = 0.0023857554949932016, iterations_used = 1
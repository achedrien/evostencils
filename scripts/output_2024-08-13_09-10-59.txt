2024-08-13 10:11:14.873 | INFO     | __main__:main:60 - ======================== Args ========================
2024-08-13 10:11:14.873 | INFO     | __main__:main:62 - structure               unet
2024-08-13 10:11:14.874 | INFO     | __main__:main:62 - downsampling_policy             lerp
2024-08-13 10:11:14.874 | INFO     | __main__:main:62 - upsampling_policy               lerp
2024-08-13 10:11:14.874 | INFO     | __main__:main:62 - num_iterations          16
2024-08-13 10:11:14.874 | INFO     | __main__:main:62 - relative_tolerance              1e-06
2024-08-13 10:11:14.874 | INFO     | __main__:main:62 - initialize_x0           random
2024-08-13 10:11:14.874 | INFO     | __main__:main:62 - num_mg_layers           6
2024-08-13 10:11:14.874 | INFO     | __main__:main:62 - num_mg_pre_smoothing            2
2024-08-13 10:11:14.874 | INFO     | __main__:main:62 - num_mg_post_smoothing           2
2024-08-13 10:11:14.874 | INFO     | __main__:main:62 - activation              none
2024-08-13 10:11:14.874 | INFO     | __main__:main:62 - initialize_trainable_parameters         default
2024-08-13 10:11:14.874 | INFO     | __main__:main:62 - optimizer               LBFGS
2024-08-13 10:11:14.874 | INFO     | __main__:main:62 - scheduler               ['step', '1', '0.99']
2024-08-13 10:11:14.874 | INFO     | __main__:main:62 - initial_lr              0.05
2024-08-13 10:11:14.874 | INFO     | __main__:main:62 - lambda_1                1
2024-08-13 10:11:14.875 | INFO     | __main__:main:62 - lambda_2                1
2024-08-13 10:11:14.875 | INFO     | __main__:main:62 - start_epoch             0
2024-08-13 10:11:14.875 | INFO     | __main__:main:62 - max_epoch               1
2024-08-13 10:11:14.875 | INFO     | __main__:main:62 - save_every              1
2024-08-13 10:11:14.875 | INFO     | __main__:main:62 - evaluate_every          5
2024-08-13 10:11:14.875 | INFO     | __main__:main:62 - dataset_root            /home/hadrien/Applications/mg_pytorch/evostencils/scripts/data/
2024-08-13 10:11:14.875 | INFO     | __main__:main:62 - num_workers             22
2024-08-13 10:11:14.875 | INFO     | __main__:main:62 - batch_size              1
2024-08-13 10:11:14.875 | INFO     | __main__:main:62 - device          cuda
2024-08-13 10:11:14.875 | INFO     | __main__:main:62 - checkpoint_root         /home/hadrien/Applications/mg_pytorch/evostencils/scripts/train/checkpoints
2024-08-13 10:11:14.875 | INFO     | __main__:main:62 - load_experiment         None
2024-08-13 10:11:14.875 | INFO     | __main__:main:62 - load_epoch              None
2024-08-13 10:11:14.875 | INFO     | __main__:main:62 - seed            1124885477
2024-08-13 10:11:14.875 | INFO     | __main__:main:62 - deterministic           False
2024-08-13 10:11:14.876 | INFO     | __main__:main:63 - ======================================================

2024-08-13 10:11:14.876 | INFO     | __main__:main:67 - [Train] Using device cuda
2024-08-13 10:11:14.876 | INFO     | __main__:main:76 - [Train] Do not enforce deterministic algorithms, cudnn benchmark enabled
2024-08-13 10:11:14.876 | INFO     | __main__:main:81 - [Train] Manual seed PyTorch with seed 1124885477

Parameter containing:
tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=torch.float64,
       requires_grad=True)
2024-08-13 10:11:15.202 | INFO     | evostencils.code_generation.trainer:__init__:138 - [Trainer] 10 training data loaded from /home/hadrien/Applications/mg_pytorch/evostencils/scripts/data/train
2024-08-13 10:11:15.202 | INFO     | evostencils.code_generation.trainer:__init__:148 - [Trainer] 0 evaluation data loaded from /home/hadrien/Applications/mg_pytorch/evostencils/scripts/data/evaluate

loss_x: tensor(6.8582, device='cuda:0', dtype=torch.float64,
       grad_fn=<MseLossBackward0>)
loss_x: tensor(0.0212, device='cuda:0', dtype=torch.float64,
       grad_fn=<MseLossBackward0>)
loss_x: tensor(0.0141, device='cuda:0', dtype=torch.float64,
       grad_fn=<MseLossBackward0>)
loss_x: tensor(0.0109, device='cuda:0', dtype=torch.float64,
       grad_fn=<MseLossBackward0>)
loss_x: tensor(0.0052, device='cuda:0', dtype=torch.float64,
       grad_fn=<MseLossBackward0>)
loss_x: tensor(0.0181, device='cuda:0', dtype=torch.float64,
       grad_fn=<MseLossBackward0>)
loss_x: tensor(0.0046, device='cuda:0', dtype=torch.float64,
       grad_fn=<MseLossBackward0>)
loss_x: tensor(0.0025, device='cuda:0', dtype=torch.float64,
       grad_fn=<MseLossBackward0>)
loss_x: tensor(0.0069, device='cuda:0', dtype=torch.float64,
       grad_fn=<MseLossBackward0>)
loss_x: tensor(0.0038, device='cuda:0', dtype=torch.float64,
       grad_fn=<MseLossBackward0>)
2024-08-13 10:11:41.239 | INFO     | evostencils.code_generation.trainer:train:209 - trainable omega = Parameter containing:
tensor([[0.1356, 0.1449, 0.0931, 0.0867, 0.1592, 0.5239, 0.0905, 0.6576, 0.9430,
         0.0370],
        [1.0574, 1.0570, 1.0566, 1.0558, 1.0565, 1.0566, 1.0559, 1.0553, 1.0544,
         1.0556],
        [1.1665, 1.1665, 1.1665, 1.1665, 1.1665, 1.1665, 1.1665, 1.1665, 1.1665,
         1.1665],
        [1.2891, 1.2891, 1.2891, 1.2891, 1.2891, 1.2891, 1.2891, 1.2891, 1.2891,
         1.2891],
        [3.0425, 3.0425, 3.0425, 3.0425, 3.0425, 3.0425, 3.0425, 3.0425, 3.0425,
         3.0425],
        [2.3884, 2.3884, 2.3884, 2.3884, 2.3884, 2.3884, 2.3884, 2.3884, 2.3884,
         2.3884],
        [1.5149, 1.5149, 1.5149, 1.5149, 1.5149, 1.5149, 1.5149, 1.5149, 1.5149,
         1.5149],
        [1.3362, 1.3362, 1.3362, 1.3362, 1.3362, 1.3362, 1.3362, 1.3362, 1.3362,
         1.3362],
        [1.0731, 1.0731, 1.0731, 1.0731, 1.0731, 1.0731, 1.0731, 1.0731, 1.0731,
         1.0731]], dtype=torch.float64, requires_grad=True), trainable weight = 0, time = 0.013806343078613281, conv_factor = 0.0055873911240653246, iterations_used = 1